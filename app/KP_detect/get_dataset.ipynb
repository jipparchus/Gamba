{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KP Detection\n",
    "## 1-1 Training Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "# from ultralytics.data.annotator import auto_annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_current = os.path.dirname(os.path.abspath('__file__'))\n",
    "os.path.split(path_current)[0]\n",
    "sys.path.append('/workspaces/MoonClimbers/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app_sys import AppSys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neffect_max = 4\n",
    "param_filtering = 1\n",
    "method_filtering = 'percent'\n",
    "generate = True\n",
    "split = True\n",
    "coco2yolo = False\n",
    "yolo_config_yaml = False\n",
    "annotate = False\n",
    "# Instance of the AppSys\n",
    "app_sys = AppSys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Effect:\n",
    "    \"\"\"\n",
    "    Frame modifications\n",
    "    \"\"\"\n",
    "    def __init__(self, neffects):\n",
    "        self.neffects = neffects\n",
    "        self.dict_effects = {\n",
    "            'resize': self.resize,\n",
    "            'rotate': self.rotate,\n",
    "            'skew': self.skew,\n",
    "            'afin': self.afin,\n",
    "            'blur': self.blur,\n",
    "            # 'noise': self.noise,\n",
    "            'gray': self.gray,\n",
    "            # 'dark': self.dark,\n",
    "            # 'light': self.light,\n",
    "            # 'color_shift': self.color_shift,\n",
    "            'color_shuffle': self.color_shuffle\n",
    "            }\n",
    "        self.get_effects()\n",
    "    \n",
    "    def get_effects(self):\n",
    "        \"\"\"\n",
    "        Get a list of effects to be applied. If 'gray' comes with 'colour shift/shuffle', remove 'colour shift/shuffle'\n",
    "        \"\"\"\n",
    "        self.list_effects = random.sample(self.dict_effects.keys(), self.neffects)\n",
    "        if 'gray' in self.list_effects:\n",
    "            try:\n",
    "                for ee in ['color_shift', 'color_shuffle']:\n",
    "                    self.list_effects.remove(ee)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    def apply_effects(self, img):\n",
    "        \"\"\"\n",
    "        Apply the effects and generate a string to log what effects were applied\n",
    "        \"\"\"\n",
    "        e = ''\n",
    "        _img = img\n",
    "        for effect in self.list_effects:\n",
    "            print(effect, _img.dtype)\n",
    "            e += f'_{effect}'\n",
    "            _img = self.dict_effects[effect](_img)\n",
    "        return _img, e\n",
    "    \n",
    "    # Utils\n",
    "\n",
    "    def gamma_correction(self, img, gamma):\n",
    "        lookup_table = np.zeros((256, 1), dtype='uint8')\n",
    "        for i in range(256):\n",
    "            lookup_table[i][0] = 255 * pow(float(i) / 255, 1.0 / gamma)\n",
    "        return cv2.LUT(img, lookup_table)\n",
    "        \n",
    "    # Geometry\n",
    "\n",
    "    def resize(self, img):\n",
    "        zoom = random.uniform(0.3, 1.)\n",
    "        # aspect = random.choice([0, 1, 4, 16])\n",
    "        h, w = img.shape[:2]\n",
    "        img = cv2.resize(img, (round(w * zoom), round(h * zoom)))\n",
    "        return img\n",
    "    \n",
    "    def rotate(self, img):\n",
    "        h, w = img.shape[:2]\n",
    "        ss = max(h, w)\n",
    "        deg = random.uniform(-179, 180)\n",
    "        if abs(deg) > 1e-3:\n",
    "            zoom = random.uniform(0.6, 1.)\n",
    "            M = cv2.getRotationMatrix2D((w / 2, h / 2), deg, zoom)\n",
    "            img = cv2.warpAffine(img, M, (round(ss * zoom), round(ss * zoom)), borderValue=(128,128,128))\n",
    "            return img\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def skew(self, img):\n",
    "        h, w = img.shape[:2]\n",
    "        deg = random.uniform(-30, 30)\n",
    "        if abs(deg) > 1e-3:\n",
    "            a = np.tan(np.deg2rad(deg))\n",
    "            M = np.array([[1, a, 0], [0, 1, 0]], dtype=np.float32)\n",
    "            img = cv2.warpAffine(img, M, (int(w + h * a), h), borderValue=(128,128,128))\n",
    "        return img\n",
    "\n",
    "    def afin(self, img):\n",
    "        \"\"\" rotate + skew, defined by projection of 3 points \"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "        pts1 = np.float32([[0, 50], [50, 0], [10, 50]])\n",
    "        pts2 = np.float32([[0, 50], [40, 10], [10, 50]])\n",
    "        M = cv2.getAffineTransform(pts1, pts2)\n",
    "        img = cv2.warpAffine(img, M, (w, h), borderValue=(128,128,128))\n",
    "        return img\n",
    "    \n",
    "    # Image sharpness\n",
    "    \n",
    "    def blur(self, img):\n",
    "        size = random.randint(3, 9)\n",
    "        img = cv2.blur(img, (size, size))\n",
    "        return img\n",
    "\n",
    "    # def noise(self, img):\n",
    "    #     noise_level = random.randint(1, 30)\n",
    "    #     noise = np.random.randint(0, noise_level, img.shape)\n",
    "    #     img = img + noise.astype('uint8')\n",
    "    #     return img\n",
    "    \n",
    "    # Colours\n",
    "\n",
    "    def gray(self, img):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        return img\n",
    "\n",
    "    # def dark(self, img):\n",
    "    #     img = self.gamma_correction(img, round(random.uniform(0.7, 1), 1))\n",
    "    #     return img\n",
    "\n",
    "    def light(self, img):\n",
    "        img = self.gamma_correction(img, round(random.uniform(1, 2), 1))\n",
    "        return img\n",
    "\n",
    "    def color_shift(self, img):\n",
    "        \"\"\"\n",
    "        Random colour shift by look-up table\n",
    "        \"\"\"\n",
    "        coeff = random.uniform(0.05, 0.8)\n",
    "        idx = np.arange(256)\n",
    "        sigmoid = 1/(1+(np.exp(-coeff*(idx - 256//2 + 1))))\n",
    "        lut = (sigmoid * 256).astype(np.uint8)\n",
    "        return cv2.LUT(img, lut)\n",
    "    \n",
    "    def color_shuffle(self, img):\n",
    "        \"\"\"\n",
    "        Shuffle RBG channels\n",
    "        \"\"\"\n",
    "        lis_bgr = list(cv2.split(img))\n",
    "        random.shuffle(lis_bgr)\n",
    "        return cv2.merge((tuple(lis_bgr)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleImage():\n",
    "    \"\"\"\n",
    "    A class to extract random frames from a video and apply random effects to them.\n",
    "    \"\"\"\n",
    "    def __init__(self, video, neffect_max=3) -> None:\n",
    "        # Max number of effects applied\n",
    "        self.neffects_max = neffect_max\n",
    "        # Number of frames to be extracted from each video\n",
    "\n",
    "        self.vpath = video\n",
    "        self.vname = os.path.split(self.vpath)[1]\n",
    "        # Directpry to save the augmented frames\n",
    "        self.saveto = app_sys.PATH_ASSET_HOLD_DETECT\n",
    "        print('save to: ', self.saveto)\n",
    "        os.makedirs(self.saveto, exist_ok=True)\n",
    "\n",
    "        # Open the video and get the number of frames\n",
    "        self.vidcap = cv2.VideoCapture(self.vpath)\n",
    "        self.num_frames = int(self.vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(self.num_frames)\n",
    "        # Extract frames from the video and apply random effects (max 3 effects)\n",
    "\n",
    "    def standardize_fsize(self, img, target_size=640):\n",
    "        \"\"\"\n",
    "        Standardize the frame size to 640x640 pixels for YOLOv8.\n",
    "        Resize while keeping the aspect ratio. Padding the frame with black pixels.\n",
    "        \"\"\"\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "        scale = target_size / max(h, w)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "\n",
    "        resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "        # Create a blank canvas with padding\n",
    "        # If grayscale image\n",
    "        if len(img.shape) == 2:\n",
    "            padded_img = np.ones((target_size, target_size), dtype=np.uint8) * 128  # Gray padding\n",
    "        else:\n",
    "            padded_img = np.ones((target_size, target_size, 3), dtype=np.uint8) * 128  # Gray padding\n",
    "        pad_top = (target_size - new_h) // 2\n",
    "        pad_left = (target_size - new_w) // 2\n",
    "        padded_img[pad_top:pad_top+new_h, pad_left:pad_left+new_w] = resized\n",
    "\n",
    "        return padded_img\n",
    "\n",
    "    def get_frame(self, nf, method):\n",
    "        \"\"\" Extract the nf-th frame / random frame of the video \"\"\"\n",
    "        # If selecting random frames, overwite nf.\n",
    "        if method == 'random':\n",
    "            nf = random.randint(0, self.num_frames - 1)\n",
    "        self.vidcap.set(cv2.CAP_PROP_POS_FRAMES, nf)\n",
    "        success, img = self.vidcap.read()\n",
    "        if success:\n",
    "            return img\n",
    "\n",
    "    def get_modified_frames(self, arg, method='percent'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            arg: - number of frames to extract per video for method == 'random'\n",
    "                 - percent of the number of frames to extract per video for method == 'percent'\n",
    "            methodf: 'random' or 'percent'\n",
    "        \"\"\"\n",
    "        if method == 'random':\n",
    "            if min(0, arg) < 0:\n",
    "                arg = 0\n",
    "            elif max(self.num_frames, arg) > self.num_frames:\n",
    "                arg = self.num_frames\n",
    "            list_nfs = np.arange(arg)\n",
    "        else:\n",
    "            if min(0, arg) < 0:\n",
    "                arg = 0\n",
    "            elif max(100, arg) > 100:\n",
    "                arg = 100\n",
    "            list_nfs = np.unique(np.linspace(0, self.num_frames-1, num=int(self.num_frames*arg/100)).astype(int))\n",
    "\n",
    "        for i in list_nfs:\n",
    "            img = self.get_frame(i, method)\n",
    "            if img is None:\n",
    "                continue\n",
    "            neffets = random.randint(0, self.neffects_max)\n",
    "            if neffets == 0:\n",
    "                img_std = self.standardize_fsize(img, target_size=640)\n",
    "                cv2.imwrite(os.path.join(self.saveto, f\"{self.vname}_{i}.jpg\"), img_std)\n",
    "            else:\n",
    "                _img = img\n",
    "                # Instance of Effect class\n",
    "                effect = Effect(neffets)\n",
    "                _img, ff = effect.apply_effects(_img)\n",
    "                img_std = self.standardize_fsize(_img, target_size=640)\n",
    "                cv2.imwrite(os.path.join(self.saveto, f\"{self.vname}_{i}_{ff}.jpg\"), img_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(lis_imgs, base=0):\n",
    "    # Rename images in the list of image names\n",
    "    imgs = [f for f in lis_imgs if f.endswith('.jpg')]\n",
    "    imgs_shuffled = shuffle(imgs, random_state=1)\n",
    "    lis_new_names = []\n",
    "    for e, i in enumerate(imgs_shuffled):\n",
    "        index = base + e\n",
    "        img_name_new = f'{index:05d}.jpg'\n",
    "        print(i, img_name_new)\n",
    "        lis_new_names.append(img_name_new)\n",
    "    return lis_new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def auto_annotater(dir_data, dir_out):\n",
    "#     # auto_annotate(data=dir_data, det_model='yolov8n.pt', sam_model='sam_b.pt', output_dir=dir_out)\n",
    "#     auto_annotate(data=dir_data, det_model='yolov8n.pt', sam_model='sam2_b.pt', output_dir=dir_out)\n",
    "#     # auto_annotate(data=dir_data, det_model='yolov9e.pt', sam_model='sam_l.pt', output_dir=dir_out)\n",
    "#     # auto_annotate(data=dir_data, det_model=os.path.join(os.getcwd(), \"results\", \"8_epochs-2\", \"weights\", \"best.pt\"), sam_model='sam_l.pt', output_dir=dir_out)\n",
    "#     # auto_annotate(data=dir_data, det_model=os.path.join(os.getcwd(), \"results\", \"8_epochs-2\", \"weights\", \"best.pt\"), output_dir=dir_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating frame images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test, valid = 'Stargaze_luke.mp4', 'Potato_has_Fallen_jonah.mp4'\n",
    "test, valid = '', ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New_Heart_Design_luke.mp4\n",
      "save to:  /workspaces/MoonClimbers/app/asset/hold_detect\n",
      "2933\n",
      "resize uint8\n",
      "afin uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_250252/3383936994.py:26: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  self.list_effects = random.sample(self.dict_effects.keys(), self.neffects)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resize uint8\n",
      "gray uint8\n",
      "rotate uint8\n",
      "gray uint8\n",
      "resize uint8\n",
      "rotate uint8\n",
      "afin uint8\n",
      "resize uint8\n",
      "gray uint8\n",
      "skew uint8\n",
      "gray uint8\n",
      "skew uint8\n",
      "blur uint8\n",
      "blur uint8\n",
      "gray uint8\n",
      "skew uint8\n",
      "color_shuffle uint8\n",
      "gray uint8\n",
      "afin uint8\n",
      "blur uint8\n",
      "rotate uint8\n",
      "gray uint8\n",
      "blur uint8\n",
      "rotate uint8\n",
      "gray uint8\n",
      "afin uint8\n",
      "gray uint8\n",
      "skew uint8\n",
      "resize uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "skew uint8\n",
      "resize uint8\n",
      "afin uint8\n",
      "gray uint8\n",
      "color_shuffle uint8\n",
      "afin uint8\n",
      "resize uint8\n",
      "skew uint8\n",
      "resize uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "blur uint8\n",
      "skew uint8\n",
      "afin uint8\n",
      "blur uint8\n",
      "resize uint8\n",
      "resize uint8\n",
      "rotate uint8\n",
      "blur uint8\n",
      "color_shuffle uint8\n",
      "MB2024_scanning.mp4\n",
      "save to:  /workspaces/MoonClimbers/app/asset/hold_detect\n",
      "3474\n",
      "blur uint8\n",
      "afin uint8\n",
      "blur uint8\n",
      "blur uint8\n",
      "resize uint8\n",
      "color_shuffle uint8\n",
      "afin uint8\n",
      "blur uint8\n",
      "rotate uint8\n",
      "resize uint8\n",
      "resize uint8\n",
      "afin uint8\n",
      "gray uint8\n",
      "resize uint8\n",
      "blur uint8\n",
      "gray uint8\n",
      "skew uint8\n",
      "resize uint8\n",
      "skew uint8\n",
      "blur uint8\n",
      "gray uint8\n",
      "skew uint8\n",
      "color_shuffle uint8\n",
      "resize uint8\n",
      "blur uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "skew uint8\n",
      "gray uint8\n",
      "rotate uint8\n",
      "resize uint8\n",
      "gray uint8\n",
      "afin uint8\n",
      "resize uint8\n",
      "rotate uint8\n",
      "color_shuffle uint8\n",
      "afin uint8\n",
      "rotate uint8\n",
      "blur uint8\n",
      "gray uint8\n",
      "color_shuffle uint8\n",
      "skew uint8\n",
      "resize uint8\n",
      "blur uint8\n",
      "resize uint8\n",
      "gray uint8\n",
      "skew uint8\n",
      "afin uint8\n",
      "blur uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "afin uint8\n",
      "resize uint8\n",
      "gray uint8\n",
      "afin uint8\n",
      "rotate uint8\n",
      "blur uint8\n",
      "color_shuffle uint8\n",
      "skew uint8\n",
      "rotate uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "gray uint8\n",
      "afin uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "afin uint8\n",
      "resize uint8\n",
      "blur uint8\n",
      "skew uint8\n",
      "Stargaze_luke.mp4\n",
      "save to:  /workspaces/MoonClimbers/app/asset/hold_detect\n",
      "717\n",
      "afin uint8\n",
      "resize uint8\n",
      "blur uint8\n",
      "gray uint8\n",
      "gray uint8\n",
      "resize uint8\n",
      "blur uint8\n",
      "blur uint8\n",
      "skew uint8\n",
      "Open_hands_zac.mp4\n",
      "save to:  /workspaces/MoonClimbers/app/asset/hold_detect\n",
      "2491\n",
      "blur uint8\n",
      "gray uint8\n",
      "blur uint8\n",
      "afin uint8\n",
      "rotate uint8\n",
      "gray uint8\n",
      "resize uint8\n",
      "rotate uint8\n",
      "afin uint8\n",
      "gray uint8\n",
      "color_shuffle uint8\n",
      "gray uint8\n",
      "blur uint8\n",
      "skew uint8\n",
      "blur uint8\n",
      "color_shuffle uint8\n",
      "afin uint8\n",
      "skew uint8\n",
      "rotate uint8\n",
      "skew uint8\n",
      "color_shuffle uint8\n",
      "blur uint8\n",
      "rotate uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "skew uint8\n",
      "rotate uint8\n",
      "blur uint8\n",
      "resize uint8\n",
      "blur uint8\n",
      "rotate uint8\n",
      "blur uint8\n",
      "gray uint8\n",
      "rotate uint8\n",
      "color_shuffle uint8\n",
      "gray uint8\n",
      "Mollys_Pinches_luke.mp4\n",
      "save to:  /workspaces/MoonClimbers/app/asset/hold_detect\n",
      "2642\n",
      "resize uint8\n",
      "rotate uint8\n",
      "skew uint8\n",
      "rotate uint8\n",
      "afin uint8\n",
      "skew uint8\n",
      "resize uint8\n",
      "resize uint8\n",
      "afin uint8\n",
      "blur uint8\n",
      "skew uint8\n",
      "blur uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "resize uint8\n",
      "blur uint8\n",
      "color_shuffle uint8\n",
      "blur uint8\n",
      "color_shuffle uint8\n",
      "resize uint8\n",
      "skew uint8\n",
      "afin uint8\n",
      "color_shuffle uint8\n",
      "afin uint8\n",
      "blur uint8\n",
      "rotate uint8\n",
      "color_shuffle uint8\n",
      "gray uint8\n",
      "afin uint8\n",
      "resize uint8\n",
      "afin uint8\n",
      "gray uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "resize uint8\n",
      "rotate uint8\n",
      "blur uint8\n",
      "skew uint8\n",
      "blur uint8\n",
      "afin uint8\n",
      "blur uint8\n",
      "rotate uint8\n",
      "afin uint8\n",
      "color_shuffle uint8\n",
      "rotate uint8\n",
      "blur uint8\n",
      "Potato_has_Fallen_jonah.mp4\n",
      "save to:  /workspaces/MoonClimbers/app/asset/hold_detect\n",
      "1272\n",
      "afin uint8\n",
      "skew uint8\n",
      "gray uint8\n",
      "resize uint8\n",
      "resize uint8\n",
      "gray uint8\n",
      "color_shuffle uint8\n",
      "gray uint8\n",
      "afin uint8\n",
      "skew uint8\n",
      "color_shuffle uint8\n",
      "skew uint8\n",
      "afin uint8\n",
      "color_shuffle uint8\n",
      "skew uint8\n",
      "blur uint8\n",
      "afin uint8\n",
      "rotate uint8\n",
      "color_shuffle uint8\n",
      "skew uint8\n",
      "afin uint8\n",
      "resize uint8\n",
      "color_shuffle uint8\n"
     ]
    }
   ],
   "source": [
    "if generate:\n",
    "    samples = os.listdir(app_sys.PATH_ASSET_RAW)\n",
    "    for sample in samples:\n",
    "        if sample.endswith('.mp4'):\n",
    "            if sample not in [test, valid]:\n",
    "                print(sample)\n",
    "                sample_ = SampleImage(os.path.join(app_sys.PATH_ASSET_RAW, sample), neffect_max)\n",
    "                sample_.get_modified_frames(param_filtering, method=method_filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset into Train, Test, Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images exists in Train directory.\n",
      "Newly added files counts staret from: 0\n",
      "Open_hands_zac.mp4_541.jpg 00000.jpg\n",
      "MB2024_scanning.mp4_631__resize_afin.jpg 00001.jpg\n",
      "Potato_has_Fallen_jonah.mp4_0__afin_skew_gray_resize.jpg 00002.jpg\n",
      "Open_hands_zac.mp4_1299__rotate.jpg 00003.jpg\n",
      "New_Heart_Design_luke.mp4_209__resize_gray.jpg 00004.jpg\n",
      "Stargaze_luke.mp4_238.jpg 00005.jpg\n",
      "New_Heart_Design_luke.mp4_1151__blur_rotate_gray.jpg 00006.jpg\n",
      "New_Heart_Design_luke.mp4_1361__gray_afin.jpg 00007.jpg\n",
      "New_Heart_Design_luke.mp4_2722__resize_rotate_blur_color_shuffle.jpg 00008.jpg\n",
      "Mollys_Pinches_luke.mp4_845.jpg 00009.jpg\n",
      "MB2024_scanning.mp4_1578__color_shuffle_resize.jpg 00010.jpg\n",
      "Open_hands_zac.mp4_1082.jpg 00011.jpg\n",
      "Mollys_Pinches_luke.mp4_422__afin_blur_skew.jpg 00012.jpg\n",
      "Potato_has_Fallen_jonah.mp4_1271__afin_resize_color_shuffle.jpg 00013.jpg\n",
      "Mollys_Pinches_luke.mp4_1690__afin.jpg 00014.jpg\n",
      "MB2024_scanning.mp4_3367__rotate_afin_resize_blur.jpg 00015.jpg\n",
      "Potato_has_Fallen_jonah.mp4_462__gray.jpg 00016.jpg\n",
      "New_Heart_Design_luke.mp4_0.jpg 00017.jpg\n",
      "Open_hands_zac.mp4_1190__rotate_skew_color_shuffle_blur.jpg 00018.jpg\n",
      "Open_hands_zac.mp4_1840.jpg 00019.jpg\n",
      "Mollys_Pinches_luke.mp4_950__resize_blur.jpg 00020.jpg\n",
      "Stargaze_luke.mp4_0__afin_resize_blur_gray.jpg 00021.jpg\n",
      "MB2024_scanning.mp4_2210__gray_color_shuffle_skew.jpg 00022.jpg\n",
      "Mollys_Pinches_luke.mp4_2007__rotate.jpg 00023.jpg\n",
      "Stargaze_luke.mp4_119.jpg 00024.jpg\n",
      "New_Heart_Design_luke.mp4_942__skew_color_shuffle_gray.jpg 00025.jpg\n",
      "New_Heart_Design_luke.mp4_1570__resize_color_shuffle_rotate.jpg 00026.jpg\n",
      "Stargaze_luke.mp4_358__gray_resize_blur.jpg 00027.jpg\n",
      "Stargaze_luke.mp4_716__skew.jpg 00028.jpg\n",
      "Potato_has_Fallen_jonah.mp4_231__resize_gray.jpg 00029.jpg\n",
      "Open_hands_zac.mp4_1732__color_shuffle_rotate.jpg 00030.jpg\n",
      "Mollys_Pinches_luke.mp4_105__rotate_afin_skew_resize.jpg 00031.jpg\n",
      "New_Heart_Design_luke.mp4_523__resize_gray_skew.jpg 00032.jpg\n",
      "Mollys_Pinches_luke.mp4_1478__gray_afin_resize.jpg 00033.jpg\n",
      "MB2024_scanning.mp4_1052.jpg 00034.jpg\n",
      "Open_hands_zac.mp4_1407.jpg 00035.jpg\n",
      "MB2024_scanning.mp4_1157__gray_skew_resize.jpg 00036.jpg\n",
      "Open_hands_zac.mp4_974__skew.jpg 00037.jpg\n",
      "Potato_has_Fallen_jonah.mp4_808.jpg 00038.jpg\n",
      "Stargaze_luke.mp4_596.jpg 00039.jpg\n",
      "Potato_has_Fallen_jonah.mp4_577__afin_skew_color_shuffle.jpg 00040.jpg\n",
      "Mollys_Pinches_luke.mp4_2429.jpg 00041.jpg\n",
      "MB2024_scanning.mp4_1894__skew_gray_rotate_resize.jpg 00042.jpg\n",
      "MB2024_scanning.mp4_841.jpg 00043.jpg\n",
      "Open_hands_zac.mp4_2273__blur_gray.jpg 00044.jpg\n",
      "Open_hands_zac.mp4_108__blur_afin.jpg 00045.jpg\n",
      "MB2024_scanning.mp4_3473__skew.jpg 00046.jpg\n",
      "Open_hands_zac.mp4_866__blur_color_shuffle_afin.jpg 00047.jpg\n",
      "Mollys_Pinches_luke.mp4_2641__afin_color_shuffle_rotate_blur.jpg 00048.jpg\n",
      "Mollys_Pinches_luke.mp4_1056__color_shuffle_blur.jpg 00049.jpg\n",
      "New_Heart_Design_luke.mp4_2513__resize.jpg 00050.jpg\n",
      "MB2024_scanning.mp4_1999__gray_afin_resize_rotate.jpg 00051.jpg\n",
      "New_Heart_Design_luke.mp4_2827.jpg 00052.jpg\n",
      "Mollys_Pinches_luke.mp4_2218__resize_rotate_blur_skew.jpg 00053.jpg\n",
      "MB2024_scanning.mp4_2946.jpg 00054.jpg\n",
      "Mollys_Pinches_luke.mp4_316__resize.jpg 00055.jpg\n",
      "Mollys_Pinches_luke.mp4_2324__blur.jpg 00056.jpg\n",
      "MB2024_scanning.mp4_526.jpg 00057.jpg\n",
      "New_Heart_Design_luke.mp4_2408__skew_afin_blur.jpg 00058.jpg\n",
      "New_Heart_Design_luke.mp4_104__resize_afin.jpg 00059.jpg\n",
      "Mollys_Pinches_luke.mp4_1373__afin_blur_rotate_color_shuffle.jpg 00060.jpg\n",
      "Open_hands_zac.mp4_2381.jpg 00061.jpg\n",
      "New_Heart_Design_luke.mp4_837__gray.jpg 00062.jpg\n",
      "MB2024_scanning.mp4_210__blur_resize_color_shuffle_afin.jpg 00063.jpg\n",
      "MB2024_scanning.mp4_2104__color_shuffle_afin_rotate_blur.jpg 00064.jpg\n",
      "New_Heart_Design_luke.mp4_2094__afin_resize_skew.jpg 00065.jpg\n",
      "Open_hands_zac.mp4_757__blur_skew.jpg 00066.jpg\n",
      "MB2024_scanning.mp4_315.jpg 00067.jpg\n",
      "Open_hands_zac.mp4_216__rotate_gray_resize.jpg 00068.jpg\n",
      "Open_hands_zac.mp4_2056__blur_rotate.jpg 00069.jpg\n",
      "MB2024_scanning.mp4_1683.jpg 00070.jpg\n",
      "Mollys_Pinches_luke.mp4_633__blur.jpg 00071.jpg\n",
      "Mollys_Pinches_luke.mp4_2112.jpg 00072.jpg\n",
      "Mollys_Pinches_luke.mp4_2535__afin_blur_rotate.jpg 00073.jpg\n",
      "New_Heart_Design_luke.mp4_418__gray_resize_rotate_afin.jpg 00074.jpg\n",
      "MB2024_scanning.mp4_1368__blur.jpg 00075.jpg\n",
      "MB2024_scanning.mp4_420__blur_rotate_resize.jpg 00076.jpg\n",
      "MB2024_scanning.mp4_105__blur.jpg 00077.jpg\n",
      "Mollys_Pinches_luke.mp4_739__color_shuffle_rotate.jpg 00078.jpg\n",
      "Open_hands_zac.mp4_0__blur_gray.jpg 00079.jpg\n",
      "Mollys_Pinches_luke.mp4_528.jpg 00080.jpg\n",
      "Open_hands_zac.mp4_1515__color_shuffle.jpg 00081.jpg\n",
      "Potato_has_Fallen_jonah.mp4_115.jpg 00082.jpg\n",
      "Potato_has_Fallen_jonah.mp4_346__color_shuffle.jpg 00083.jpg\n",
      "Mollys_Pinches_luke.mp4_1795__gray.jpg 00084.jpg\n",
      "New_Heart_Design_luke.mp4_1780.jpg 00085.jpg\n",
      "New_Heart_Design_luke.mp4_1675.jpg 00086.jpg\n",
      "Open_hands_zac.mp4_1948__skew_rotate_blur_resize.jpg 00087.jpg\n",
      "New_Heart_Design_luke.mp4_628__gray_skew_blur.jpg 00088.jpg\n",
      "MB2024_scanning.mp4_3052__blur_color_shuffle_skew_rotate.jpg 00089.jpg\n",
      "Open_hands_zac.mp4_433__rotate_afin_gray_color_shuffle.jpg 00090.jpg\n",
      "Mollys_Pinches_luke.mp4_1584.jpg 00091.jpg\n",
      "New_Heart_Design_luke.mp4_1256__blur_rotate.jpg 00092.jpg\n",
      "Open_hands_zac.mp4_2490__rotate_color_shuffle_gray.jpg 00093.jpg\n",
      "New_Heart_Design_luke.mp4_733__blur.jpg 00094.jpg\n",
      "New_Heart_Design_luke.mp4_1989__afin_gray_color_shuffle.jpg 00095.jpg\n",
      "New_Heart_Design_luke.mp4_1047__afin.jpg 00096.jpg\n",
      "New_Heart_Design_luke.mp4_2303__blur.jpg 00097.jpg\n",
      "New_Heart_Design_luke.mp4_2199__resize_color_shuffle_rotate.jpg 00098.jpg\n",
      "Mollys_Pinches_luke.mp4_1901__color_shuffle.jpg 00099.jpg\n",
      "MB2024_scanning.mp4_1473__gray_skew.jpg 00100.jpg\n",
      "MB2024_scanning.mp4_2841__resize_gray_afin_rotate.jpg 00101.jpg\n",
      "Potato_has_Fallen_jonah.mp4_1039__rotate.jpg 00102.jpg\n",
      "0 images exists in Test directory.\n",
      "Newly added files counts staret from: 0\n",
      "New_Heart_Design_luke.mp4_314__rotate.jpg 00000.jpg\n",
      "Potato_has_Fallen_jonah.mp4_693__skew_afin.jpg 00001.jpg\n",
      "Mollys_Pinches_luke.mp4_1267__resize_skew_afin_color_shuffle.jpg 00002.jpg\n",
      "New_Heart_Design_luke.mp4_1884__skew_resize.jpg 00003.jpg\n",
      "MB2024_scanning.mp4_736__gray_resize.jpg 00004.jpg\n",
      "New_Heart_Design_luke.mp4_1466__gray_skew.jpg 00005.jpg\n",
      "Open_hands_zac.mp4_1623__rotate.jpg 00006.jpg\n",
      "MB2024_scanning.mp4_2315__resize.jpg 00007.jpg\n",
      "Mollys_Pinches_luke.mp4_211.jpg 00008.jpg\n",
      "MB2024_scanning.mp4_2736__rotate_afin.jpg 00009.jpg\n",
      "Open_hands_zac.mp4_324.jpg 00010.jpg\n",
      "MB2024_scanning.mp4_1262__skew.jpg 00011.jpg\n",
      "MB2024_scanning.mp4_1789__blur_color_shuffle_rotate.jpg 00012.jpg\n",
      "0 images exists in Validation directory.\n",
      "Newly added files counts staret from: 0\n",
      "MB2024_scanning.mp4_0__blur_afin.jpg 00000.jpg\n",
      "Mollys_Pinches_luke.mp4_1162__color_shuffle.jpg 00001.jpg\n",
      "MB2024_scanning.mp4_2420__blur_resize_gray_skew.jpg 00002.jpg\n",
      "MB2024_scanning.mp4_947__blur.jpg 00003.jpg\n",
      "Stargaze_luke.mp4_477__blur.jpg 00004.jpg\n",
      "Mollys_Pinches_luke.mp4_0__resize_rotate_skew.jpg 00005.jpg\n",
      "New_Heart_Design_luke.mp4_2617.jpg 00006.jpg\n",
      "Open_hands_zac.mp4_2165.jpg 00007.jpg\n",
      "MB2024_scanning.mp4_2631__color_shuffle.jpg 00008.jpg\n",
      "MB2024_scanning.mp4_3262__rotate_gray_afin_color_shuffle.jpg 00009.jpg\n",
      "MB2024_scanning.mp4_2525__afin_blur.jpg 00010.jpg\n",
      "Open_hands_zac.mp4_649__gray.jpg 00011.jpg\n",
      "MB2024_scanning.mp4_3157__color_shuffle.jpg 00012.jpg\n"
     ]
    }
   ],
   "source": [
    "if split:\n",
    "    direc_data = app_sys.PATH_ASSET_HOLD_DETECT\n",
    "    files = os.listdir(direc_data)\n",
    "    imgs = [f for f in files if f.endswith('.jpg')]\n",
    "    X = shuffle(imgs, random_state=1)\n",
    "    train, test_valid = train_test_split(X, test_size=0.2, random_state=1)\n",
    "    test, valid = train_test_split(test_valid, test_size=0.5, random_state=1)\n",
    "    dict_data = dict(zip([\"Train\", \"Test\", \"Validation\"], [train, test, valid]))\n",
    "    for ndirec in dict_data.keys():\n",
    "        new_direc = os.path.join(direc_data, ndirec)\n",
    "        os.makedirs(new_direc, exist_ok=True)\n",
    "        n_pre_exist = len(os.listdir(new_direc))\n",
    "        print(f'{n_pre_exist} images exists in {ndirec} directory.\\nNewly added files counts staret from: {n_pre_exist}')\n",
    "        for nfile, nfile_new in zip(dict_data[ndirec], rename(dict_data[ndirec], base=n_pre_exist)):\n",
    "            # Number of files exist in the directory already.\n",
    "            os.rename(os.path.join(direc_data, nfile), os.path.join(new_direc, nfile_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if coco2yolo:\n",
    "    for mode in [\"train\", \"valid\"]:\n",
    "        cocojson_dir = os.path.join(os.getcwd(), \"data\", mode, f\"{mode}.json\")\n",
    "        imgs_dir = os.path.join(os.getcwd(), \"data\", mode, \"images\")\n",
    "        txt_dir = os.path.join(os.getcwd(), \"data\", mode, \"labels\")\n",
    "        with open(cocojson_dir) as f:\n",
    "            cocojson = json.load(f)\n",
    "        print(cocojson.keys())\n",
    "        for img in cocojson[\"images\"]:\n",
    "            print(img[\"id\"])\n",
    "            anns = [ann for ann in cocojson[\"annotations\"] if ann[\"image_id\"] == img[\"id\"]]\n",
    "            w, h = img[\"width\"], img[\"height\"]\n",
    "            if len(anns) > 0:\n",
    "                with open(os.path.join(txt_dir, img[\"file_name\"].split(\".\")[0] + \".txt\"), \"w\") as ff:\n",
    "                    for ann in anns:\n",
    "                        # Yolo txt label counts labels from zero\n",
    "                        category = ann[\"category_id\"] - 1\n",
    "                        # Normalise the coordinates between 0 and 1\n",
    "                        polygon = ann[\"segmentation\"][0]\n",
    "                        norm_polygon = [format(coord / w if i % 2 == 0 else coord / h, \".6f\") for i, coord in enumerate(polygon)]\n",
    "                        ff.write(f\"{category} \" + \" \".join(map(str, norm_polygon)) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yolo_config_yaml:\n",
    "    class_names = [\"hold\", \"volume\", \"wall\", \"mat\"]\n",
    "    nc = len(class_names)\n",
    "    path = os.path.join(os.getcwd(), \"data\")\n",
    "    train_dir = os.path.join(path, \"train\", \"images\")\n",
    "    valid_dir = os.path.join(path, \"valid\", \"images\")\n",
    "    test_dir = \"\"\n",
    "    config = {\n",
    "        \"names\": class_names,\n",
    "        \"nc\": nc,\n",
    "        \"path\": path,\n",
    "        \"train\": train_dir,\n",
    "        \"val\": valid_dir\n",
    "    }\n",
    "    with open(os.path.join(os.getcwd(), \"data.yaml\"), \"w\") as f:\n",
    "        yaml.dump(config, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if annotate:\n",
    "#     dir_data = os.path.join(os.getcwd(), \"data\", \"train\", \"unused\")\n",
    "#     dir_out = os.path.join(os.getcwd(), \"data\", \"train\", \"unused\", \"label\")\n",
    "#     auto_annotater(dir_data, dir_out)\n",
    "\n",
    "#     from random import randint\n",
    "\n",
    "#     img = cv2.imread(os.path.join(dir_data, \"sample1.mp4_0.jpg\"))\n",
    "#     h, w = img.shape[:2]\n",
    "#     with open(os.path.join(dir_out, \"sample1.mp4_0.txt\"), 'r') as f:\n",
    "#         labels = f.read().splitlines()\n",
    "\n",
    "#     for label in labels:\n",
    "#         class_id, *poly = label.split(' ')\n",
    "\n",
    "#         poly = np.asarray(poly, dtype=np.float16).reshape(-1, 2)  # Read poly, reshape\n",
    "#         poly *= [w, h]  # Unscale\n",
    "\n",
    "#         cv2.polylines(img, [poly.astype('int')], True, (randint(0, 255), randint(0, 255), randint(0, 255)), 2)  # Draw Poly Lines\n",
    "\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
